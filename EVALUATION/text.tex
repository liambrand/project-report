\part{Evaluation}
	\chapter{Introduction}
	The Evaluation aims to take a critical look at the product and how well it satisfied the requirements. This will involve reviewing all hardware and software aspects of the system and discussing their strengths and weaknesses, with appropriate evidence to back up these discussions. 
	
	Following this will be an evaluation of the process that was undertaken to create the product. This will entail a discussion of any positives such as skills acquired and lessons learned as well as negatives such as performance problems. There will also be a discussion of potential alternative project plans using the benefit of hindsight to determine what might be done differently a second time around for the project to have enjoyed more success.
	
	Finally there will be conclusions and recommendations. Project aims will be compared against work carried out, and conclusions will be drawn summing up what has been done and what it means. Following this, recommendations for further work will be discussed in the context of the project's wider scope.
	
	\chapter{Product Evaluation}
	This chapter aims to be an evaluation of the product, comparing its functionality against the initial product requirements. Each of the requirements will be listed in turn, with a discussion of what evidence has been used to surmise how well it did or didn't meet the requirement, followed by a conclusion on whether or not the requirement was ultimately satisfied. The primary requirements identified for the product can be found in \ref{requirements}.
	
		\subsection{Functional Requirements}
		The first of the requirements is that the developed robot must be capable of movement. Tests performed in the synthesis pertaining to movement had some initial success with the robot being capable of moving in basic directions when the commands to do so were hard coded into the microcontroller's program, but the system tests showed that this movement did not serve much practical purpose during the robot's operation. It was not capable of dynamically changing its movement, only of travelling in whatever direction was hard coded into it. What was initially envisioned was a more dynamic and universal method of movement, with the robot changing its direction during operation for things like obstacle avoidance. It was also envisioned that this movement wouldn't be simple directions, but a complete omndirectional movement capability. Instead of employing a few different methods for basic movement, the robot should have taken heading and distances to attempt to calculate the correct force that would need to be exerted on each wheel in order to drive it in the appropriate direction in the appropriate speed. Alternatively it could have used a simpler method of movement like the one implemented by Borenstein and Koren\cite{borenstein1988obstacle} for a simple nursing robot, where the only movement done is either a pure rotation or moving forward in the direction its facing. As well, the movement should have been dynamic and consistently dictated by the main program to steer the robot out of the way of obstacles. Using the robot's observation capacity, distance readings from the LIDAR sensor could have been used to determine if obstacles were close to the robot. If they were, the robot should have detected this and immediately changed its heading to navigate around them. The primary justification behind these pieces of functionality can be seen in the mobile robotics section of the analysis, where it is repeatedly mentioned that movement and range finding were used for obstacle avoidance in a few different projects. For these reasons, it is believed this requirement has not been satisfied.
		
		The second of the functional requirements is that the robot must be capable of observation. Initial integration testing for the observational capability showed promise, the microcontroller proved capable in controlling basic sensor functions as it was able to start, stop and retrieve data from the LIDAR sensor. This functionality didn't prove to be less effective during the system test either, as during the system test it still demonstrated the ability to take readings and store them to the Micro-SD Card medium. For these reasons, it is believed that this requirement was satisfied by the product. Despite this, the implementation could have been a bit more sophisticated. The returned readings data features an attribute called quality which indicates the validity and accuracy of the reading. Before being written to the buffer, this attribute should have been checked with low quality readings being discarded. This would mean only readings the sensor is confident are correct are written to the file and in turn, would mean the generated map would likely be more accurate. As well, the LIDAR supports a 'get health' request where it returns information pertaining to its current state, indicating if there is a warning or an error. This could have been called before the LIDAR sensor began its scanning to ensure right at the start of the robot's operation that the sensor was in a good state to begin outputting data.
		
		The final functional requirement was that the observational data must be processed into a map. The actual GUI that was to process the observational data was produced and during testing demonstrated that it was capable of reading observational data in the format that the LIDAR and microcontroller's file writer system produced it in. When tests observed whether or not the produced map was accurate to the environment the readings were taken in however, it was immediately apparent that the readings were not properly processed. As well, even if this did work the readings should have been processed in a more efficient way. The best alternative to this simplistic mapping was the use of the CSM software discussed in the analysis, as this would have provided a much more sophisticated map and could have incorporated localization data from the robot as well. For these reasons, it is believed that this requirement was not satisfied.
	
		\subsection{Non-Functional Requirements}
		The first non-functional requirement of build quality concerned the physical soundness of the robot's construction. Examples of this not being satisfied are things like wired snagging the motors or LIDAR sensor, and components falling out of the structure during operation. System testing didn't observe any stray wires interfering with components, but the microcontroller battery's ground cable had a habit of slipping out of the ground port despite repeatedly being screwed in. For this reason, it is believed the non-functional requirement has not been met.
		
		The second non-functional requirement concerns the robot's operational speed. Key aspects highlighted in the requirement's explanation was that the scanning session should take less than ten seconds, and the map generation less than thirty. Some success was had here, with the robot able to obtain several thousand samples in under the given time ensuring that it operated at an appropriate speed. Unfortunately it was unable to be determined whether or not the GUI could generate a map in a sufficient time frame because the map it did produce was completely inaccurate. Whilst it produced this in a reasonable time, this could simply be because it was processed wrong and processing it right could involve a map generation that takes much longer. It therefore cannot be concluded that the system has a satisfactory operational speed, and as such this requirement has not been satisfied.
		
		The third and fourth non-functional requirements concern the mapping procedure. As mentioned previously in the operational speed discussion and shown during the mapping integration tests and the system tests, the produced system is incapable of producing a map that represents the scanned environment. Given it's inability to fulfill the base requirement of producing a map, the requirements for this mapping to be adaptable and consistent have not been satisfied.	
	
		\subsection{Conclusions}
		The majority of requirements outlined in the analysis have not been satisfied by the produced work, and this was primarily reflected by the numerous failed tests of the systems test conducted in the synthesis' testing stage. On the whole it is believed that the product failed to satisfy the original project aims of creating a self navigational drone, and using it for SLAM purposes. 
	
	\chapter{Process Evaluation}
	\label{evaluation:processevaluation}
	The purpose of the process evaluation is to take a critical standpoint on how the project as a whole was approached. This will concern aspects such as how well the project was managed, what has been learned from the project during its undertaking and what would be done differently a second time around now that there is the benefit of hindsight.
	
	
		\section{Objectives}
		Most of the objectives outlined in the Terms of Reference have been met. Knowledge of embedded systems has certainly been enhanced thanks to project aspects such as making use of embedded documentation for different pieces of hardware, utilising embedded libraries to attain different pieces of functionality, and in particular connecting and controlling peripherals (e.g. the LIDAR sensor) using an embedded system. 
		
		Knowledge of LIDAR and SLAM has also been attained from the literature review. The literature review for mobile robotics contained a section on LIDAR, and a good number of different resources were used to understand how LIDAR worked, the strengths and weaknesses of the technology, and also some of the different projects that have employed LIDAR and why they have chosen to do so. The same goes for SLAM, as the fundamentals of the SLAM problems have been properly reviewed and understood in its respective investigation. As well, a greater understanding of SLAM's usage in the wider world has been attained. Thanks to this investigation the viability of how SLAM might be achieved with the drone was understood better as well. Based on what knowledge was achieved by SLAM, an appropriate investigation into how the data might be processed was conducted and was met with a conclusion that helped define a key element of the overall system.
		
		Due to time constraints and developmental problems however the drone's construction was never really completed. Physically, the goal of construction was met given the assembly of the chassis and the fitting of some relevant components. Software-wise however the drone cannot be considered complete as its functionality is incredibly basic, lacking aspects such as obstacle avoidance and dynamic movement. As well, the inability of the created system to perform SLAM lends itself further to the argument that construction hasn't been achieved. Before this objective can be met, a more thorough implementation of movement should be realised as well as a proper implementation of the system's mapping capabilities. 
		
		With regards to a proper evaluation of the product against the relevant aims and objectives, that can be called a success given the previous chapter discussing precisely this. The objective of discussing and evaluating how the project could be taken further is to follow at the end of the Evaluation.
		
		\section{Skills}
		The first skill outlined in the Terms of Reference is for the improvement of basic electronics assembly capability. This has been satisfied, proved by a physical implementation of the drone being mostly realised with an assembled chassis, microcontroller and LIDAR sensor all connected to each other. As well, the design featured a section discussing how the drone's power supply would be determined with consideration paid to voltages and battery capacity to calculate what sort of operational runtime could be expected from different power sources. Based on these things, it's concluded that this skill has definitely improved.
		
		Embedded engineering skills were improved significantly as well. As previously discussed, the implementation of the robot's program on a microcontroller allowed for a greater appreciation of writing embedded software. As well, one aspect that was entirely new to the author was connecting different components to the microcontroller and manipulating them through the microcontroller's software. Establishing a connection between the LIDAR sensor and microcontroller and then being able to control the sensor through commands the microcontroller sent to it was new territory for the author, and the reasonable success of an observational functionality with the robot is proof that the understanding of this has been developed.
		
		An improved understanding of \LaTeX has definitely been obtained from the project. Through the usage of online tutorials and resources the fundamentals behind creating a \LaTeX document were understood, and this allowed for the entirety of the project report itself to be written in \LaTeX. Not only has this allowed for a greater understanding of it as a technology, but an appreciation of the different features such as easier formatting, easier code insertion and the multitude of external libraries has been developed.
		
		The skill that has probably made the least progress in the report is the knowledge of different SLAM algorithms. The fundamentals behind SLAM have been well researched and written about, and evidence of their understanding can be seen in the SLAM investigation in the analysis. The problem with understanding the ins and outs of the different SLAM algorithms was how complex they were. Whilst the basics were understood, once the details of each of the algorithms such as the Extended Kalman Filter were discussed there was too much of a knowledge gap to understand. More preliminary research into SLAM might have helped to improve this skill. 
		
		\section{Project Plan}
		Initially the project was approached well. Outlined in the project plan, the initial objectives during the first few weeks were to create the Project Initiation Document and the Terms of Reference, as well as to begin some reading into any relevant hardware documentation that had been established as potentially useful at the very beginning of the project. These were all achieved, and the initial objectives of the build phase involving creating some basic programs and hardware tests also went ahead fine. This gave some early confidence thanks to goal achievement, and the objectives were well designed as relevant project documentation was handed in on time and some preliminary knowledge of what might be used to create the project was garnered and understood. The Ethics form too was submitted on time and the marking scheme in the project handbook was reviewed, affording a good understanding of what the project report would entail. The project's initiation then was well planned which assisted in it being well executed.
		
		Issues began to show themselves in November however, when the project's build objectives began to ramp up. The initial build tasks of creating a dummy board program and testing the LIDAR sensor being used for the project went ahead fine, and basic notes on the product's design were made in preparation for starting a draft on the design section. One task wasn't followed properly at this point, with the task of establishing communication between the microcontroller and the LIDAR sensor being attempted before the construction of the physical chassis. This was attempted first due to some overconfidence attained from previous work with the hardware, and a big problem was very quickly encountered. The previously studied SDK's documentation states that the rplidar.h file simply needs to be included to gain LIDAR functionality, but when this was done the program gave file dependency errors during compile attempts. The most prominent error was an import problem where files within the SDK were unable to import the file sys/ioctl.h. Looking into this, ioctl.h appeared to be a linux kernel header file. The first attempt to fix this was simply making sure these kernel files were working properly, so APT was used to install or update the linux kernel headers. Other packages such as build-essentials were also installed, but none of these things fixed the problem. One other potential problem was that maybe there was a program somewhere relying on 32bit libraries which the 64bit Ubuntu OS didn't have, so APT was used to install the i386 architecture as well as some relevant packages to allow for better 32bit support. This didn't fix anything either. In a last ditch effort some of the kernal header files were actually copied into the LIDAR SDK, but this just resulted in other dependency problems coming up.	In the Project Plan this task was estimated at taking around two weeks to complete, but at this point a month had elapsed and there was still no progress. In response to these failures the approach of using the SDK was abandoned, and an attempt to manually incorporate the protocol outlined in the observational section of the design chapter was attempted. Data structures of bytes were made and sent to the LIDAR through the serial connection byte by byte with a similar approach being used to retrieve the data it sent back. First attempts at doing this were unsuccessful, and it was a while before the LIDAR began sending something back. Interrupt methods that retrieved characters from the serial channel were configured, triggered by the presence of a character on the RxBuffer. Once this was done, data began being received at a steady rate. After this bytes began being stored into structs representing response descriptors and the structure of the responses themselves. Then the response data that was being retrieved from the LIDAR was converted to binary through the use of a byte lookup table that changed a given byte into its binary representation. This was due to how each bit in each byte had a specific purpose, an example of this can be seen in fig \ref{fig:protocolbreakdown} in the design chapter. This still didn't really work, because most of the requests sent to the LIDAR didn't receive valid responses. For example the protocol documentation stated that the get health request returned three bytes but whenever it was tested it only returned two. As well, a request to stop the scanning procedure would immediately stop all data output and any subsequent attempts to start the scanning process again wouldn't work, requiring a hard reset of the board. By this point it was late December. Attempting to get the two components set up had consumed a lot of time, and the project report and product build had fallen behind massively. The analysis draft was only half finished and no physical aspect of the robot had been realized. Getting the two components communicating was completely abandoned as a task, and previous tasks involving creating drafts of report sections and assembling the robot's chassis were addressed. In hindsight, the decision to do this really should have been taken sooner.
		
		Moving into the second semester, the lack of progress with a robot created the discussion of how a map might be created and displayed to a user. This discussion resulted in the goal of a GUI being created to process and display observational data to the user. The decision of this goal at this point in the project led to it not being included in the Project Plan, which further worsened the planning issues. Regardless, before February was over a basic GUI had been made that showed a matplotlib instance with some dummy points plotted and the robot's chassis had been assembled with a battery pack power source on the way. As the semester went on, the massively behind analysis was worked on to try and create a draft and work was done to attempt to implement the robot's movement functionality. By March, a drone capable of basic movement had been created, meaning November's objective of having an automated drone was massively overdue. Partially this was due to developmental problems, partially it was due to mis-allocated time as what time had been spent on the project was wasted attempting to fix problems with the LIDAR sensor, and partially this was due to the incredibly over optimistic timescale of the plan's objectives. Looking back, achieving an automated drone in the space of a few weeks with just 30 hours of work is an incredibly naive goal, and far more time should have been dedicated to it. As well, 'automate drone' is a very vague and general objective, and should have been broken down into tasks of a more granular nature. This would have allowed for a clearer understanding of what needed to be done, a better time estimation, and an easier time meeting goals which would have helped boost confidence and morale during the project. 
		
		Eventually a solution to the sensor problem was stumbled upon in the form of a modified SDK from an open source project that used the LIDAR sensor with an arduino based robot, and communication between the LIDAR sensor and the microcontroller was established. By this point in the report, there was only an analysis draft and a rough draft of the synthesis' design and implementation sections, and a lack of product and report progress incited some panic and caused a few unsound decisions to be made. At the start of the product's development, a skeleton OS comprising of just one file was created. From this, different bits of functionality were tested and hacked in to get them working. For example with the movement, the control class discussed in the design wasn't implemented and was simply put in the main program as getting it working was the priority. As more and more code like this was added to get different things working, this initial prototype main file formed the basis of what little functionality had been implemented. When attempts were made to break it down into classes, memory issues were encountered and the already massively constrained schedule meant this problem couldn't be rectified, resulting in the robot's main program not resembling what was outlined in the design chapter at all.
		
		This entire mismanagement of time, underestimation of task complexity and overestimation of personal skill manifested itself the most in the testing. Because of development time being so overstretched, far less time was left for thorough testing. Unit tests couldn't be conducted on time meaning individual pieces of code couldn't be tested to ensure they behaved as expected, meaning there's no way of knowing how truly stable or unstable the system is. The bulk of the testing was the integration tests performed during the robot's development. The integration tests, whilst useful, were improper given the project's methodology. The project methodology outlined in the design was a prototyping style, aiming to first develop a high level prototype and then fill in functionality. The bottom up style of integration testing does not lend itself well to this approach as it focuses on modular functionality. A better approach for integration testing would have been a top down style, where the higher integration levels are tested with lower level modules being simple stubs that only simulate their functionality. This would have resulted in a quicker prototype, an earlier achievement of the robot chassis construction and less time spent working out low level specifics which ate up the time of later objectives.
		
		On the whole, the primary issues with the process were as follows. First was a vast underestimation of task complexity, more time should have been given to tasks to accommodate for problems. Second was too much tunnel visioning on tasks. After a few weeks of failure with the LIDAR, it should have immediately been abandoned and focus diverted elsewhere to prevent the project from falling even further behind. Third was poorly planned testing. Testing should have been given greater thought earlier on in the project to avoid a testing style that clashed so violently with the outlined methodology. In the future, time taken to deal with task failures should be thought about a lot more when deciding on task time frames. As well, a greater awareness of the wider project should be kept in mind to help prevent getting bogged down in very difficult problems and allowing them to consume too much development time, as well as to help ensure aspects like methodologies and approaches to different things like testing mesh well together.
	
		\section{Choice of Equipment and Techniques}
		This section aims to explore the strengths and weaknesses of the tools and techniques employed during the project's undertaking. This will primarily be achieved by looking at what the original reasons were for employing a tool or technique, and comparing these reasons with how the tool or technique served the project during development.
		
		The majority of tools employed during the project's development were appropriate for their purpose. The three wheeled chassis provided a stable, easy to assemble platform to house the components of the robot. Whilst the dead reckoning aspect discussed in the techniques was never realised, the initial planning for it to possibly be incorporated into the robot's function was still a good idea and the encoders that came on the chassis motors would have helped with this. As well, even though omnidirectional movement was never implemented, the wheels and layout of them lent themselves well to supporting universal movement.
		
		The lack of accurate map generation means it is unclear whether or not the sensor was a good choice. The myriad of issues encountered attempting to have it interface with the microcontroller were likely due to a lack of research prior to its usage rather than any fault with the design itself, so it wouldn't be fair to say that this issues meant it was not an appropriate choice. Initial reasoning behind it having a high sample rate and an SDK to afford it accuracy and premade functional implementation was sound however.
		
		As mentioned before, memory issues plagued the software aspect of the robot when it was being broken down into the classes outlined in the class diagram. Mbed OS appears to feature relatively user friendly ways of being able to load programs onto the board and have their memory usage tracked. Micro C possess similar features but they aren't quite as elegant, and inexperience with hardware led to this being a huge blocker for implementing the software's proposed class design. This problem never really went away and resulted in the final program being only a single class, a far cry from the intended functional decomposition that could be been achieved if the class diagram had been properly implemented. In hindsight, Mbed OS was likely a better choice owing to its better documentation and syntactic sugar. Usage of an IDE supporting breakpoints of the embedded code like Keil Microvision might have helped here as well. A microcontroller with more memory potentially could have been used here as well, but given the relatively high amount of memory available on the K64F its likely this memory problem was due to a design problem somewhere rather than an insufficient board.
	
	\chapter{Conclusions and Recommendations}
		\section{Conclusions}	
		A degree of success have been enjoyed with regards to the project's aims and skills. As previously discussed, skills outlined in the Terms of Reference such as embedded engineering ability have been furthered during the project's planning and development. As well, small objectives pertaining to acquiring knowledge on fields such as SLAM and LIDAR have seen success, and at this point the project and its respective process has been evaluated against the project's aims and objectives. The main aim of the project however was to develop a self navigational mapping drone, and this aim has ultimately not been met.
		
		The existing implementation is a simple chassis composed of powered motors driven by a microcontroller, capable of only incredibly basic movement. The implementation possesses an observational capability, but due to the lack of a mapping functionality it is unknown whether or not the observations the robot takes and writes to a file are accurate.
		
		The main issue was how the project was approached, rather than any core equipment issues. The choice of equipment was for the most part solid. The microcontroller offered all necessary functionality that was needed, the chassis was quick to assemble and housed the necessary components without issue, and from what has been understood of the LIDAR sensor it proved capable of observation. As previously discussed, a different choice of Operating System would have been better however, Mbed OS' additional more user friendly features likely would have helped with issues encountered during the project such is with memory allocation errors.
		
		The project's approach is what was the most lacking. Tasks weren't allocated enough time and more thought should have been given to time management following the failure of certain tasks rather than focusing on how things would go if everything went successful. As well, enough thought was not put into some of the approaches used. For example, the bottom up integration testing approach encountered issues with the project's prototyping methodology. 
		
		\section{Recommendations for Further Work}
		With regards to the project itself, more work will be needed on refining the movement system to ensure the robot is capable of true universal movement. This will involve the implementation of mathematical sums to calculate how much force each wheel needs to be able to move in any heading in a 360 degree circle. As well, obstacle detection will need to be implemented if the robot is to have any navigational success, using sensor readings to detect when there are obstructions that need to be moved around. Finally, the mapping capability requires a lot more work. A working template GUI is there but it doesn't do much. Ensuring that the GUI processes readings correctly would be an upgrade, but the ultimate goal would be the implementation of CSM allowing the system to truly generate a proper map. The wireless transmission functionality discussed in the analysis could also be implemented to send any signals back to a terminal if the robot detect that it has become stuck or encountered a different issues. Taking it further, the robot could be linked to a mobile control interface allowing an operator to easily remote control it from their phone or tablet. The map could also be generated in real time and sent back to said tablet so that the operator could see it forming in real time, rather than having the robot need to return where data can be collected manually from the Micro SD-Card.
		
		Viewing the technologies of the project in a wider scope, the functionality could attempt to be implemented in more complex environments. For example, acquiring a drone kit and affixing an omnidirectional sensor to it could allow for airborne mapping to be performed. An attempt could also be made to construct a submersible that is capable of underwater travel whilst mapping. These would significantly drive up the cost of the project however.
		
		Looking at the extreme end of this technology's implementation, versions of the robot that are capable of withstanding environments like outer space could be used for planetary exploration. One or perhaps many of these robots traversing a planets surface and mapping it with millimeter precision would likely provide scientific information of incredible value.
